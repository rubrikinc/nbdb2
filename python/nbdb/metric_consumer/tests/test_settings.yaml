sparse_store:
  # Number of data point keys in a single partition
  partition_size: 3
  # Log metrics which are dropping less than this threshold.
  # Range: 0.0 to 1.0
  drop_ratio_log_threshold: 0.001
  enable_stream_transforms: false
  forced_write_interval: 86400
  gen_sparse_data_distribution: false

  rollups:
    report_clock_skew: true

  sparse_algos:
    min_delta: 0.0001
    # Number of seconds after which a data point is forced to be written even if it has not changed
    forced_write_interval: 43200
    quantile: .9
    window_size: 10

  sparse_telemetry:
    # Log metrics which are dropping less than this threshold.
    # Range: 0.0 to 1.0
    drop_ratio_log_threshold: 0
    gen_sparse_data_distribution: false

  # Stats related settings
  stats:
    # How many stats objects are cached in memory
    cache_size: 1000000
    # triggers an expensive byte size scan this will impact throughput, should be done sparingly
    # ideally disabled on production and maybe enabled on one metric consumer to get an idea
    telemetry_report_interval_seconds: 1800

  # Settings for heartbeat scan algorithm that detects missing data points and marks them with a tombstone
  heartbeat_scan:
    # very aggressive setting because in local run we do not generate with real - clock
    # but generate data akin to a historical import, so the heart beat scan may not run before the test is done
    interval: 600
    # A missing point marker is added if the current datapoint is not within
    # `data_gap_detection_interval` seconds of the previous datapoint
    data_gap_detection_interval: 120
    # A series is terminated and a tombstone marker is added if no datapoints
    # are seen within `termination_detection_interval` seconds
    termination_detection_interval: 720

  # Default TTL for all metrics
  ttl_days: 1

# We allow the ability to "trace" certain metrics. The tracing config is
# periodically pulled from an S3 location
tracing_config:
  s3_bucket:
  s3_key:
  # We check S3 ever `refresh_interval` seconds to see if a new config was
  # uploaded
  refresh_interval: 600

sql_api:
  workers: 10
  store_read_workers: 10
  index_search_workers: 2
  default_group_by_interval: 60

batch_writers:
  # Workers used by the batch_writer thread pool
  # These are the DataBatchWriter, StatsBatchWriter and IndexingBatchWriter
  # A single process can have atmost 2 of these workers
  workers: 1

schema_creator:
  druid_topic_prefix: "anomalydb_druid"
  num_workers: 1

metric_consumer:
  kafka_brokers: "kafka:9092"
  topic: "metrics"
  group_prefix: "random"
  num_consumers: 10
  metric_protocol: influx
   # We flush our writes every 60 secs
  flush_writes_period_secs: 60
  whitelist_cluster_uuid:
  whitelist_node_id:
  # Messages with timestamp older than this will be logged
  past_message_lag: 8640000
  # Messages with timestamp newer than this will be logged
  future_message_lag: 3600

  redis_host: "anomalydb-redis"
  redis_port: 6379

recovery_consumer:
  num_consumers: 1

sparse_kafka:
  connection_string:
    brokers: ['localhost:9123']
    batch_size: 1000
  write_workers: 1

redisdb:
  write_workers: 1

logging:
  log_metrics: false

telemetry:
  protocol: influx
  # We add the environment tag to all metrics
  environment: test
  influx:
    # Interval in seconds at which frequency the metrics are pushed to graphite
    reporting_interval: 600
    prefix: "anomalydb"
    database: "anomalydb-metrics"
    server: "test.com"
    port: 80
