version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    expose:
      - "2181"

  redis:
    image: redis:3.0.7
    # port 6379

  kafka:
    image: wurstmeister/kafka:2.11-2.0.0
    links:
      - zookeeper
    # port 9092
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_HOSTNAME: kafka
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_DELETE_TOPIC_ENABLE: "true"

  flask:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/api/home.py",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--schema_mapping=batch:nbdb/config/schema.yaml",
              "--wait_for_conn=kafka:9092,redis:6379"]
    # port 5000
    depends_on:
      - kafka
      - redis
    environment:
      ANOMALYDB_SECRETS_BUCKET: anomalydb-batch-ingest
      ANOMALYDB_SECRETS_OBJECT: testcases/secrets/creds.txt
    # Need to link to AWS credentials file to download secrets from S3
    volumes:
      - {{ home_dir }}/.aws/credentials:/root/.aws/credentials

  realtime_metric_consumer:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/metric_consumer/metric_consumer_app.py",
              "--consumer_mode=realtime",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=kafka:9092"]
    # For gdb like debugging with pyrasite, we need to relax security
    # for the container
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    depends_on:
      - kafka

  rollup_metric_consumer:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/metric_consumer/metric_consumer_app.py",
              "--consumer_mode=rollup",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=kafka:9092"]
    # For gdb like debugging with pyrasite, we need to relax security
    # for the container
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    depends_on:
      - kafka

  sparse_batch_consumer:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/batch_consumer/sparse_batch_consumer_app.py",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=kafka:9092"]
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    depends_on:
      - kafka

  dense_batch_consumer:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/batch_consumer/dense_batch_consumer_app.py",
              "--consumer_mode=both",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--batch_filter_file=nbdb/config/batch_metrics_filter.yaml",
              "--wait_for_conn=kafka:9092"]
    security_opt:
      - seccomp:unconfined
    cap_add:
      - SYS_PTRACE
    volumes:
      - {{ home_dir }}/.aws/credentials:/root/.aws/credentials
    environment:
      # Reprocess messages in systest even if sparse JSONs exist
      - SKIP_PREVIOUSLY_PROCESSED=0
    depends_on:
      - kafka

  test_metric_producer:
    image: anomalydb:local
    entrypoint: ["python3"]
    command: ["nbdb/load_simulator/test_metric_producer.py",
              "--setting_file=nbdb/config/settings_darwin.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=kafka:9092",
              "--setup=1",
              "--local",
              "--start_cluster_id=0"]
    depends_on:
      - kafka
