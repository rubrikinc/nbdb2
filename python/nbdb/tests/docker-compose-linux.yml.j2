version: '2'
services:
  zookeeper:
    image: wurstmeister/zookeeper:3.4.6
    network_mode: host
    # port 2181

  redis:
    image: redis:3.0.7
    network_mode: host
    # port 6379

  kafka:
    image: wurstmeister/kafka:2.11-2.0.0
    network_mode: host
    # port 9092
    environment:
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://127.0.0.1:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_HOSTNAME: 127.0.0.1
      KAFKA_ZOOKEEPER_CONNECT: 127.0.0.1:2181
      KAFKA_DELETE_TOPIC_ENABLE: "true"

  flask:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/api/home.py",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--schema_mapping=batch:nbdb/config/schema.yaml",
              "--wait_for_conn=127.0.0.1:9092,127.0.0.1:6379"]
    # port 5000
    depends_on:
      - kafka
      - redis
    environment:
      ANOMALYDB_SECRETS_BUCKET: anomalydb-batch-ingest
      ANOMALYDB_SECRETS_OBJECT: testcases/secrets/creds.txt
    # Need to link to AWS credentials file to download secrets from S3
    volumes:
      - {{ home_dir }}/.aws/credentials:/root/.aws/credentials

  realtime_metric_consumer:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/metric_consumer/metric_consumer_app.py",
              "--consumer_mode=realtime",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=127.0.0.1:9092"]
    depends_on:
      - kafka

  rollup_metric_consumer:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/metric_consumer/metric_consumer_app.py",
              "--consumer_mode=rollup",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=127.0.0.1:9092"]
    depends_on:
      - kafka

  sparse_batch_consumer:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/batch_consumer/sparse_batch_consumer_app.py",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=127.0.0.1:9092"]
    depends_on:
      - kafka

  dense_batch_consumer:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/batch_consumer/dense_batch_consumer_app.py",
              "--consumer_mode=both",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--batch_filter_file=nbdb/config/batch_metrics_filter.yaml",
              "--wait_for_conn=127.0.0.1:9092"]
    volumes:
      - {{ home_dir }}/.aws/credentials:/root/.aws/credentials
    environment:
      # Reprocess messages in systest even if sparse JSONs exist
      - SKIP_PREVIOUSLY_PROCESSED=0
    depends_on:
      - kafka

  test_metric_producer:
    image: anomalydb:local
    network_mode: host
    entrypoint: ["python3"]
    command: ["nbdb/load_simulator/test_metric_producer.py",
              "--setting_file=nbdb/config/settings_linux.yaml",
              "--schema_mapping=default:nbdb/config/schema.yaml",
              "--wait_for_conn=127.0.0.1:9092",
              "--setup=1",
              "--local",
              "--start_cluster_id=0"]
    depends_on:
      - kafka
